# 论文口头汇报提纲

## 一、开场（1-2分钟）

### 1.1 研究背景（通俗版）

**问题是什么？**
想象一下，你有一群无人机，要让它们一起飞遍一片农田、森林或者灾区，把每个地方都检查一遍。这就是"覆盖规划"——让无人机们分工合作，把整个区域都走一遍，不要有遗漏，也不要重复走。

**实际应用场景：**
- **农业监测**：几架无人机一起检查大片农田，看哪里需要浇水、施肥
- **林业巡护**：在森林里巡逻，找火灾隐患、病虫害
- **灾后评估**：地震、洪水后，快速了解哪些地方受灾严重

**现在遇到什么困难？**
就像让几个人一起走迷宫，如果迷宫变大了、人变多了、障碍物变多了，问题就来了：

1. **地图变大、无人机变多**：
   - 就像从"10×10的小地图"变成"24×24的大地图"
   - 从"1-2架无人机"变成"4-6架无人机"
   - 传统方法（Q-Learning）就像一个人要记住所有可能的情况，脑子装不下，算不过来

2. **障碍物变多**：
   - 就像迷宫里墙变多了，有些地方被隔开，无人机可能被困在某个角落
   - 障碍密度从0（没有障碍）到0.20（20%的地方是障碍）
   - 无人机之间容易"撞车"或者"重复走"，效率很低

**简单总结：**
- 传统方法在小地图、少无人机、无障碍时还行
- 但当地图变大、无人机变多、障碍变多时，就"算不动"、"协调不好"了
- 我们需要一个更聪明的方法，让多架无人机能自动分工、互相配合，高效完成任务

### 1.2 研究目标（通俗版）

**我们要做什么？**
我们想找一个更聪明的方法，让多架无人机能在"大地图、多障碍"的情况下，还能高效地一起完成任务。

**具体来说：**
- **大地图**：24×24的网格（相当于576个格子，比之前研究常用的144个格子大4倍）
- **多无人机**：4-6架无人机一起工作
- **高障碍**：20%的地方是障碍物（之前研究多在5%以下）

**验证什么？**
1. **可扩展性**：地图变大4倍，性能会不会大幅下降？（我们希望下降不超过10%）
2. **鲁棒性**：障碍物变多，无人机还能不能稳定完成任务？（我们希望即使20%障碍，覆盖率还能达到75%以上）

**打个比方：**
就像测试一个团队，在更大的场地、更复杂的环境下，还能不能高效协作完成任务。

---

## 二、方法介绍（3-4分钟）

### 2.1 QMIX核心机制
- **单调值分解**：$\frac{\partial Q_{total}}{\partial Q_i} \geq 0$，保证局部贪心=全局最优
- **架构**：环境层 → 智能体层（FC1-GRU-FC2）→ 混合层（Hypernetwork）→ 动作选择
- **优势**：训练复杂度O(N|S||A|)，推理复杂度O(N)，优于集中式方法的O(N²)

### 2.2 两项关键改进

#### 改进1：势能型奖励塑形
- **未访问距离势能**：$\Phi_{unvisited} = \frac{d_{max}-d_i}{d_{max}}$，鼓励探索未覆盖区域
- **障碍清晰度势能**：$\Phi_{obstacle} = \exp(-d_i^{obs}/\sigma)$，抑制障碍边缘低效游走
- **效果**：显著提升早期探索效率

#### 改进2：动态探索与恢复机制
- **触发条件**：当覆盖率滑动均值 $m_t < 0.9 \times m_{best}$ 时
- **恢复策略**：
  1. 回滚至最佳checkpoint
  2. 临时提升ε至0.3，快速衰减恢复
  3. 50 episode冷却期
- **效果**：在24×24、p=0.20场景下，失败率从18%降至4%

---

## 三、实验结果（3-4分钟）

### 3.1 实验设置
- **配置**：3种地图大小（12×12, 16×16, 24×24）× 2种UAV数量（4, 6）× 4种障碍密度（0, 0.05, 0.10, 0.20）= **24组组合**
- **训练**：每组600 episodes，随机种子1234，保证可复现

### 3.2 关键结果

#### 障碍密度影响
- **无障碍（0.0）**：平均覆盖率 **97.8%** ± 0.012
- **低障碍（0.05）**：平均覆盖率 **93.9%** ± 0.015
- **中障碍（0.10）**：平均覆盖率 **87.3%** ± 0.018
- **高障碍（0.20）**：平均覆盖率 **77.5%** ± 0.025（24×24场景）
- **统计显著性**：p=0.004（Wilcoxon检验）

#### 可扩展性验证
- **地图放大（12→24）**：覆盖率仅下降 **9.5%**，证明良好可扩展性
- **UAV数量（4→6）**：平均提升 **9.4%**，在p=0.20下提升4.3%（p=0.007），体现协作优势

#### 训练稳定性
- 动态恢复机制避免后期策略崩溃
- 最终覆盖率稳定在0.76±0.01（24×24, 4 UAV, p=0.20）

---

## 四、主要贡献（1-2分钟）

1. **方法扩展**：首次将QMIX应用于24×24、障碍密度0.20的多UAV覆盖任务
2. **任务塑形**：设计"未访问距离+障碍清晰度"势能组合，提升探索效率
3. **稳定训练**：提出动态探索-恢复机制，将高障碍失败率从18%降至4%
4. **系统评估**：在24组配置上开展系统评测，提供完整可复现代码与数据

---

## 五、讨论与展望（1-2分钟）

### 5.1 局限性
- **训练时间**：24×24-6UAV需38.4 GPU·h（RTX-3090），成本较高
- **理论上限**：障碍0.20时，理论覆盖率上限86%，我们达到80%，差距6%主要受步数约束
- **实时性**：当前推理时间12 ms/步，需进一步优化至<3 ms以满足机载CPU要求

### 5.2 未来工作
- 引入量化GRU与知识蒸馏，降低推理时间
- 扩展到3D地形与动态障碍场景
- 探索GNN+QMIX的拓扑泛化能力

---

## 六、总结（30秒）

- 本文成功将QMIX应用于大规模、高障碍密度的多UAV覆盖任务
- 在24×24、障碍密度0.20场景下取得77.5%的覆盖率
- 通过势能奖励与动态恢复机制保证训练稳定性
- 代码与数据已开源，满足Sensors期刊的可复现性要求

---

## 可能的问题与回答

### Q1: 为什么选择QMIX而不是其他MARL方法？
**A**: QMIX通过单调值分解保证局部贪心与全局最优一致，训练复杂度O(N|S||A|)优于集中式方法的O(N²)，且推理复杂度O(N)适合实时部署。

### Q2: 为什么高障碍密度下覆盖率下降？
**A**: 障碍密度升高导致可达区域碎片化，局部最优路径数量激增。理论上限分析表明，p=0.20时受隔离区域影响，上限约86%，我们达到80%，差距6%主要受步数约束限制。

### Q3: 动态恢复机制的具体工作原理？
**A**: 监控覆盖率滑动均值，当低于历史最佳90%时触发：回滚至最佳checkpoint、临时提升探索率ε至0.3、设置50 episode冷却期。该机制在24×24、p=0.20场景将失败率从18%降至4%。

### Q4: 实验的可复现性如何保证？
**A**: 所有实验使用固定随机种子1234，每组运行600 episodes，提供完整CSV日志与Python脚本，执行`python submissions/sensors/repro/reproduce_all.py`可一键复现所有图表。

### Q5: 与现有方法相比的优势？
**A**: 现有方法多在12×12-20×20、p≤0.15场景测试，本文在更具挑战的24×24、p=0.20场景下验证，证明QMIX在大规模、高障碍密度下的可扩展性与鲁棒性。

---

## 汇报时间分配建议

- **开场+背景**：2分钟
- **方法介绍**：4分钟
- **实验结果**：4分钟
- **贡献+讨论**：2分钟
- **总结**：1分钟
- **预留问答**：2-3分钟

**总计**：约13-15分钟（适合15-20分钟汇报）

---

## 关键数据速查表

| 指标 | 数值 |
|------|------|
| 无障碍覆盖率 | 97.8% ± 0.012 |
| 高障碍（0.20）覆盖率 | 77.5% ± 0.025 |
| 地图放大（12→24）下降 | 9.5% |
| UAV增加（4→6）提升 | 9.4% |
| 动态恢复失败率降低 | 18% → 4% |
| 训练时间（24×24-6UAV） | 38.4 GPU·h |
| 推理时间 | 12 ms/步 |
| 实验组合数 | 24组 |
| 每组训练episodes | 600 |

